{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5bbff0",
   "metadata": {},
   "source": [
    "<h1> Convolutional Neural Networks </h1>\n",
    "<p> Convolutional Neural Networks (CNNs) are a type of neural network used in image classification and signal processing problems. CNNs have been around since the 1980s but only recently became useful as it became practical to train them with the advent of faster computers and bigger and better datasets (so called \"Big Data\" (Buzzword alert)) CNNs have two main layer types: convolutional layers and pooling layers. One way to think about the conceptual difference between these convolutional layers in the CNN and the hidden layers (dense layers) in the simple neural net (Multi-layer-perceptron) used to classify the fashion-mnist dataset is that the dense layers detect patterns in specific places, while the convolutional layers detect patterns regardless of where they occur in the image. This is because the correlation operation the convolutional layer implements detects correlations with the feature map at all points in the image. For example, if the convolutional layers learn to detect eyes in a face on the left side of an image, they will also detect those eyes in the same face flipped horizontally so that the eyes are on the right side of the image. This is in contrast to a dense layer which only learns those features in the specific place they are appearing. </p>\n",
    "<p> The two main operations and thus the three main layer types CNNs implement are convolutional layers, pooling layers, and fully connected layers. Convolutional layers should really be called cross-correlation layers. Recall the definition of the convolution of f and g: (f * g) </p>\n",
    "<br>\n",
    "$$\n",
    "(f * g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) g(t - \\tau) d \\tau\n",
    "$$\n",
    "<p> Now the convolution is just the cross-correlation of two functions f(t) and g(t), except before the cross correlation is computed, f or g is flipped horizontally about the y axis. Therefore we can write the cross-correlation like so:</p>\n",
    "$$\n",
    "(f \\star g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) g(t + \\tau) d \\tau\n",
    "$$\n",
    "<img src=\"./conv_vs_corr.png\">\n",
    "<h2> Convolutional Layers </h2>\n",
    "<p> You can see the similarity. So the \"convolutional\" layers usually perform this cross-correlation operation on their inputs. When the layer is trained well, this acts to extract features from the image, as the neurons in the layer arrange themselves into feature maps, which are outputted to the next layer as they are activated. As you pass through more and more convolutional layers, the features you are cross-correlating for become more and more complicated. For example, the first layer might be straight lines, the next layer might be curves, the next layer might be basic shapes. This is another difference between CNNs and dense neural networks, convolution layers output feature maps, while dense layers output numerical values. </p>\n",
    "<p> In more detail, convolutional layers have 3 main properties:</p>\n",
    "<ul> \n",
    "    <li>Input size: Size of input image</li>\n",
    "    <li>Filters: corresponds to a certain pattern that appears in the input data. These filters are identified and refined over time as the network is trained. Can have as many as you want. Amount and content of filters changes over time as the network is trained. </li>\n",
    "    <li>Sample size of filters: The size of a filter we have. </li>\n",
    "</ul>\n",
    "<img src=\"filter_example.png\">\n",
    "<p> Example convolutional layer input on the left, and example learned filter on the right. </p>\n",
    "<h2> Pooling Layers </h2>\n",
    "<p>The pooling layers simplifies the image to increase the invariance of the neural network to translation, scaling and skewing of the features it is trying to identify. </p>\n",
    "<h2> Fully Connected / Dense layers </h2>\n",
    "<p> Once the feature maps have been outputted by the convolutional layers and averaged by the pooling layers they are passed to the fully connected layers which are the same as dense hidden layers in multi-layer perceptrons. The image is then classified based on its feature maps. </p>\n",
    "<h2> Image data for CNNs </h2>\n",
    "<p> In the previous jupyter notebooks, we had 2d data. Image data that CNNs operate on are actually 3d. There is the height, width, and the RGB color channels, which are made up of red (0-255.0), green (0-255.0), and blue (0-255.0). So the shape of a x * y image in memory will be x*y*3. Thus you can think of image data as a stack of pixels layers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4992af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
